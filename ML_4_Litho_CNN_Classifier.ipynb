{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning For Lithography\n",
    "## Unit IV : Convolutional Neural Networks\n",
    "\n",
    "### Introduction\n",
    "\n",
    "The Convolutional Neural Network (CNN) is a class of neural networks that are able to be trained efficiently for many problems, through exploitation of sparse connectivity between the neurons.  They are particularly useful for many communication problems where there is some justification for a strong prior that data can be organized in a list or matrix such that data outside of a local neighborhood can be assumed to be associated with zero weight.\n",
    "\n",
    "A CNN architecture is attractive for a photoresist model because we have strong prior beliefs that the most important information about the photoresist contour position can be found near the rising and falling edges of the aerial image signal., and that the importance of the aerial image signal with regard to a specific contour point position diminishes with distance.\n",
    "\n",
    "Like the linear classifier, the network is trained with a  a dataset D consisting of training input data samples X and labels y(X).  \n",
    "\n",
    "Also, the acceptable values of y are in a finite set of N different classifications C={c1, c2, ...cN}.\n",
    "\n",
    "In the script we  will call the number of different classifications \"n_classes.\"\n",
    "\n",
    "The number of features per input sample X is 48x48 = 2304.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preamble\n",
    "This section imports some necessary packages and helper functions that enable our script.\n",
    "\n",
    "Of particular importance is TensorFlow, here imported as \"tf,\" which is the nickname by which we will be able to access it in our script.  TensorFlow is our machine learning framework, enabling definition of the model form, definition of the training and validation procedures, definition of the model prediction method, and implementation of the training and prediction procedures.\n",
    "\n",
    "We also import numpy, which we will reference with the nickname \"np\".  The name \"numpy\" is short for \"numerical python\".  The numpy package is a critical cornerstone of the data science workflow, providing intuitivce and interactive support for arrays in a fashion that will be familiar to those who have previously done work in matlab.\n",
    "\n",
    "The matplotlib library is a nice set of tools for looking at our aerial images.\n",
    "\n",
    "The methods loaded from \"classes\" are little helper functions I wrote to make the demo script you see more compact and focused on Machine Learning rather than munging data and logs and visualizations.\n",
    "\n",
    "The preamble also sets some useful variables that help keep our log data separate from the other model forms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from classes.Visualizations import *\n",
    "from classes.Data import  loadResNIST\n",
    "from classes.Specs import specs\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR='./resNIST/'\n",
    "LOGDIR = './cnn_classifier_logs/'\n",
    "PROJECTORDIR=LOGDIR+'projector/'\n",
    "scopes=['NetLayer/LogitsLayer/Logits:0','NetLayer/MetricsLayer/labels:0']\n",
    "summary_writer = tf.summary.FileWriter(LOGDIR)\n",
    "image_size=48\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Transform Data\n",
    "In this code block we are loading our data into four blocks:\n",
    "1. **train_data** : the input training data **X**, representing a set of samples of aerial images, each 48x48 pixels. \n",
    "2. **train_labels** : the label **y(X)**, belonging to one of 11 classes, **c in C={0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10}**.  These class labels are integers, but they represent the proportion of the pixel vicinity that is \"covered\" by photoresist after development. A 0 denotes \"not covered.\" A 1 denotes \"fully or 100% covered.\"  Each increase in the index of the label correspondes to in increase in resist coverage of 10%.\n",
    "3. **eval_data** : these samples **X** are held out from training so that we may evaluate the variance and detect potential overfitting.\n",
    "4. **eval_labels** : these labels are sued in conjunction with **eval_data** to help detect overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels , eval_data, eval_labels    = loadResNIST(DATADIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Estimator\n",
    "\n",
    "There is not a canned CNN estimator so we will write a custom estimator \"from scratch.\"  however, we will use the Keras layers API (which is incorporated into newer versions of TensorFlow) and this makes it very easy!\n",
    "\n",
    "I add a little helper function as well which enables us to quickly build a sequence of CNN layers, including convolutions, activations, pooling/resizing, and dropouts, with the simple command \"conv_resize_dropout_layer.\"\n",
    "\n",
    "We provide a few variables to defien the learning rate and l2 regularization strength, as well as dropout rate.\n",
    "\n",
    "Then we define the input layer and connect it to the tensorflow variable named \"x\" which we will feed with our training and validation data.\n",
    "\n",
    "In this example we will use a 5-layer CNN.  At the layer closets to the input, the kernels will be rather large, 11x11, and there will be 8 of them. The result will be a list of 8 feature maps that represnt the activations of the first layer, which will be presnted to layer2.  but furst we will downsample the images to 19x19 (this is a kind of \"pooling\").\n",
    "\n",
    "The story is similar for layer 2, except that will use smaller kernels, 3x3.  Also we will resize the feature maps into 8 small 8x8 maps. \n",
    "\n",
    "Layer 3 uses 3x3 kernels again.  The output feature maps are smaller still. Keep in mind that each time we do a convolution, we bring information in to the center point from surrounding points. This means that if we keep doing convolutions on the same original large images, the values on the outer edges will no longer be valid (since we will be convolving with unknown values outside of the edges of the provided image.  So we shrink the image size each layer due not only to pooling, but also to convolution. \n",
    "\n",
    "The final layer is different from all of the others and resembles the LinearClassifier we started our lab exercises with: for each output class, a linear filter will be learned that maps from the output activations of layer 4 to the predicted unscalled relative class probability which we will call logits.\n",
    "\n",
    "Since we are using a custom estimator, we must not only define the model form but also specify how the model interacts with procedures that ask it for predictions. We also must define the model training procedure, which again uses softmax cross entropy loss and the gradient descent optimizer.  We also must define how the estimator should be validated, but we use the built-in accuracy metric to make this very easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode):\n",
    "    \"\"\"Model function for CNN.\"\"\"\n",
    "    from classes.CNNUtils import conv_resize_dropout_layer, log_images\n",
    "    dropout_rate=0.10 #1\n",
    "    l2_scale=0.0001 #.001\n",
    "    learning_rate=0.001\n",
    "    with tf.variable_scope('NetLayer'):\n",
    "    # Input Layer\n",
    "        input_layer = tf.cast(tf.reshape(features[\"x\"], [-1, image_size, image_size, 1],name=\"x0\"), tf.float32)\n",
    "        log_images('input_image',input_layer)\n",
    "    # Convolutional Neural Net\n",
    "        conv1 = conv_resize_dropout_layer(input_layer, filters=8,  kernel_size=[11,11], \n",
    "                                          mode=mode,   resize=[19,19], l2_scale=l2_scale,\n",
    "                                          rate=dropout_rate ,name='conv1')\n",
    "        conv2 = conv_resize_dropout_layer(conv1,       filters=8, kernel_size=[3,3],\n",
    "                                          mode=mode,   resize=[3,3],   l2_scale=l2_scale, \n",
    "                                          rate=dropout_rate, name='conv3') \n",
    "        conv3 = conv_resize_dropout_layer(conv2,       filters=16, kernel_size=[3,3],  \n",
    "                                          mode=mode,                   l2_scale=l2_scale,\n",
    "                                          rate=dropout_rate, name='conv4') \n",
    "        conv4 = conv_resize_dropout_layer(conv3,       filters=11, kernel_size=1, \n",
    "                                          mode=mode,                   \n",
    "                                          ) \n",
    "    # Logits Layer\n",
    "        with tf.variable_scope('LogitsLayer'):\n",
    "            logits=tf.reshape(conv4, [-1,11],name='Logits')\n",
    "            tf.summary.histogram('Logits', logits)\n",
    "            tf.logging.info('Logits Layer build successful..')\n",
    "\n",
    "    # Generate predictions (for PREDICT and EVAL mode)\n",
    "        predictions = {\n",
    "        \"classes\": tf.argmax(input=logits, axis=1),\n",
    "        \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "        }\n",
    "        if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "            return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "        \n",
    "    # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "        l2_loss=tf.losses.get_regularization_loss()\n",
    "\n",
    "\n",
    "        print(vars)\n",
    "        with tf.variable_scope('MetricsLayer'):\n",
    "            labels = tf.identity(labels, name='labels')            \n",
    "        cross_entropy_loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "        loss=tf.add(cross_entropy_loss,l2_loss)\n",
    "\n",
    "        tf.summary.scalar(\"cross_entropy_loss\",cross_entropy_loss)\n",
    "        tf.summary.scalar(\"l2_loss\", l2_loss)\n",
    "        tf.summary.scalar(\"loss\", loss)\n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "            train_op = optimizer.minimize(\n",
    "                loss=loss,\n",
    "                global_step=tf.train.get_global_step())\n",
    "            return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "        evalhook = SessionHook(PROJECTORDIR, scopes)\n",
    "        eval_metric_ops = {\n",
    "            \"accuracy\": tf.metrics.accuracy(\n",
    "            labels=labels, predictions=predictions[\"classes\"])}\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode, loss=loss, eval_metric_ops=eval_metric_ops, evaluation_hooks=[evalhook])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The code then defines two input functions, one for training (**train_input_fn**) and one for evaluation (**eval_input_fn**), according to the \"numpy_input_fn\" spec which helps facilitate feeding tensorflow batches of samples.  We indicate that the training input function will be fed from the **train_data** and **train_labels** variables, and likewise the evaluation input function will be fed from the **eval_data** and **eval_labels** variables.\n",
    "\n",
    "For training we specify a mini-batch size, which determines how how many samples are averaged together in determining an update direction for adjusting the weights.  \n",
    "\n",
    "During training we shuffle the dataset before breaking it into mini-batches, to prevent correlations from data preparation from skewing results or avoid reliance on lucky fits.  However, to ensure consistency when evaluating the data during training we do not shuffle during evaluation.\n",
    "\n",
    "Finally, we take the 48x48 image for each input sample and break it into a long 2304 row, with each pixel belonging to its own \"feature column\" for every image.  This feature_column will be the front end of our TensorFlow model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": train_data},\n",
    "    y=train_labels,\n",
    "    batch_size=32,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": eval_data},\n",
    "    y=eval_labels,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the RunConfig facility of the tf.estimator to hspecify how frequently we want to checkpoint the model (save intermediate results.). This also influences how frequently we will perform validation.\n",
    "\n",
    "Having defined the model function, including its form, prediction mode, training mode, and evaluation mode, we now call the tf.estimator.Estimator to actually build our classifier in TensorFlow, and then call it \"cnn_classifier.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config=tf.estimator.RunConfig(save_checkpoints_steps=1000)\n",
    "cnn_classifier = tf.estimator.Estimator(\n",
    "    model_fn=cnn_model_fn, \n",
    "    config=config,\n",
    "    model_dir=LOGDIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plan on using the \"train_and_eval\" method provided for the tf.estimator class, because it automates a periodic evaluation of the model during training, generating occasional checkpoints and then loading those checkpoints in to assess the model performance on the evaluation data.  In order to do this we need to activate the \"logger\" that logs data, and we need to define the **train_spec** and **eval_spec** which specify some of the details of the process, including directories for logged data, duration of the training process and frequency of logged data.\n",
    "\n",
    "The function \"specs\" is a little helper function I wrote for added compactness of this lab exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(logging.INFO)\n",
    "train_spec, eval_spec = specs(train_input_fn, eval_input_fn, \n",
    "                              logdir=LOGDIR, projectordir=PROJECTORDIR, \n",
    "                              max_train_steps=10000, eval_steps = 100, \n",
    "                              scopes = scopes, name = 'cnn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this elegant line of code we ask tensorflow to begin the training process, with periodic evaluation, using the cnn_classifier model and the training and eval specs we previously defined. Nice and compact!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.estimator.train_and_evaluate(cnn_classifier, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code prepares the data and metadata for plotting in TensorBoard using the Principal Components Analysis (PCA) and t-SNE projection methods for visualizing in high-dimensions.  The prepare_projector and prepare_sprites functions are little tidy script I wrote to simplify the lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_projector(PROJECTORDIR, scopes)\n",
    "prepare_sprites(PROJECTORDIR, eval_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how we can evaluate the accuracy of the model independent of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results = cnn_classifier.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a specific example by picking an index and using the \"matplotlib\" library to make a nice picture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(eval_data[11])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
